{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/workspace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX2DEhmC_0pb",
        "outputId": "b780878a-f003-4dd4-906b-db0af72be20c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M4DsdgI57ezY"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "def get_avg_time(time_1, time_2):\n",
        "    # 将时间字符串转换为时间间隔\n",
        "    format_string = '%H:%M:%S.%f'\n",
        "    time1_obj = datetime.strptime(time_1, format_string)\n",
        "    time2_obj = datetime.strptime(time_2, format_string)\n",
        "\n",
        "    # 计算时间间隔的总和\n",
        "    total_time = time1_obj - datetime.min + (time2_obj - datetime.min)\n",
        "\n",
        "    # 计算平均时间间隔\n",
        "    average_time = total_time / 2\n",
        "\n",
        "    # 将平均时间间隔格式化为相同的时间字符串格式\n",
        "    average_time_str = (datetime.min + average_time).time().strftime(format_string)\n",
        "    return average_time_str"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTimeAndText(ass_path):\n",
        "    with open(ass_path, 'r', encoding='utf-16') as file:\n",
        "        lines = file.readlines()\n",
        "    keyword = \"zhengwen\"\n",
        "    avg_time_list = []\n",
        "    text_list = []\n",
        "    for line in lines:\n",
        "        if line.startswith('Dialogue') and keyword in line:\n",
        "            content = line.split(\":\", 1)[1].strip()\n",
        "            line_list = content.split(\",\")\n",
        "            avg_time = get_avg_time(line_list[1], line_list[2])\n",
        "            avg_time_list.append(avg_time)\n",
        "            text_list.append(line_list[-1])\n",
        "    return avg_time_list, text_list"
      ],
      "metadata": {
        "id": "6sZv5EqZ727K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import subprocess\n",
        "\n",
        "def extract_frame_at_time(video_path, output_path, time_stamp):\n",
        "    ffmpeg_cmd = [\n",
        "        'ffmpeg',\n",
        "        '-ss', time_stamp,\n",
        "        '-i', video_path,\n",
        "        '-vframes', '1',\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    subprocess.run(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# for id in [str(x).zfill(2) for x in range(15, 29)]:\n",
        "data = []\n",
        "ass_path = f\"Haruhi_all/[CASO][Suzumiya_Haruhi_no_Yuuutsu][27][BDRIP][1920x1080][x264_FLAC_2][B3301EC5].SC.ass\"\n",
        "video_path = f\"Haruhi_all/[CASO][Suzumiya_Haruhi_no_Yuuutsu][27][BDRIP][1920x1080][x264_FLAC_2][B3301EC5].mkv\"\n",
        "\n",
        "avg_time_list, text_list = getTimeAndText(ass_path)\n",
        "\n",
        "for i in range(len(avg_time_list)):\n",
        "    time_stamp = avg_time_list[i]\n",
        "    output_path = f'haruhi_data/images_28/{text_list[i]}{avg_time_list[i]}.jpg'\n",
        "    extract_frame_at_time(video_path, output_path, time_stamp)\n",
        "    data.append({\"text\":str(text_list[i]), \"timestamp\":str(avg_time_list[i]), \"path\":f\"{text_list[i]}{avg_time_list[i]}.jpg\"})\n",
        "\n",
        "with open(f'haruhi_data/info_28.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "rwunO9Cw8joW"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}